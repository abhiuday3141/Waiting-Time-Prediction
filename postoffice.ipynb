{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import os\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from tensorflow.python import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_len(filename):\n",
    "    with open(filename) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_read(path, numberOfRows):\n",
    "    indexCounter = 0\n",
    "    with open(path,'r') as file:\n",
    "        nRows = numberOfRows\n",
    "        nColumns = 4\n",
    "        dataset = np.zeros(shape=(nRows, nColumns))\n",
    "        times_arrival = []\n",
    "        for line in file:\n",
    "            try:\n",
    "                dataInstance = line.split(',')\n",
    "                time_arrival = dataInstance[1] #splits the line at the comma and takes the first bit\n",
    "                time_arrival = dt.datetime.strptime(time_arrival, '%H:%M')\n",
    "                hour_arrival = time_arrival.hour\n",
    "                minute_arrival = time_arrival.minute\n",
    "                waitingMinutes = dataInstance[2]\n",
    "                serviceMinutes = dataInstance[3]\n",
    "\n",
    "                times_arrival.append(time_arrival)\n",
    "                dataset[indexCounter] = [hour_arrival, minute_arrival, waitingMinutes, serviceMinutes]\n",
    "                indexCounter = indexCounter + 1\n",
    "            except:\n",
    "                #print('index' + str(indexCounter) + 'error')\n",
    "                pass\n",
    "    return dataset, times_arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading PostOffice1Week1Day3that contains1019 entries\n",
      "Reading PostOffice1Week1Day4that contains801 entries\n",
      "Reading PostOffice1Week1Day5that contains521 entries\n",
      "Reading PostOffice1Week2Day1that contains988 entries\n",
      "Reading PostOffice1Week2Day2that contains683 entries\n",
      "Reading PostOffice1Week2Day3that contains547 entries\n",
      "Reading PostOffice1Week2Day4that contains1020 entries\n",
      "Reading PostOffice1Week2Day5that contains788 entries\n",
      "Reading PostOffice1Week3Day1that contains999 entries\n",
      "Reading PostOffice1Week3Day2that contains989 entries\n",
      "Reading PostOffice1Week3Day3that contains1000 entries\n",
      "Reading PostOffice1Week3Day4that contains1050 entries\n",
      "Reading PostOffice1Week3Day5that contains981 entries\n",
      "Reading PostOffice1Week4Day1that contains856 entries\n",
      "Reading PostOffice1Week4Day2that contains980 entries\n",
      "Reading PostOffice1Week4Day3that contains1056 entries\n",
      "Reading PostOffice1Week4Day4that contains898 entries\n",
      "Reading PostOffice1Week4Day5that contains995 entries\n",
      "Reading PostOffice2Week1Day1that contains1033 entries\n",
      "Reading PostOffice2Week1Day2that contains788 entries\n",
      "Reading PostOffice2Week1Day3that contains1001 entries\n",
      "Reading PostOffice2Week1Day4that contains909 entries\n",
      "Reading PostOffice2Week1Day5that contains930 entries\n",
      "Reading PostOffice2Week2Day1that contains747 entries\n",
      "Reading PostOffice2Week2Day2that contains923 entries\n",
      "Reading PostOffice2Week2Day3that contains871 entries\n",
      "Reading PostOffice2Week2Day4that contains763 entries\n",
      "Reading PostOffice2Week2Day5that contains889 entries\n",
      "Reading PostOffice2Week3Day1that contains970 entries\n",
      "Reading PostOffice2Week3Day2that contains684 entries\n",
      "Reading PostOffice2Week3Day3that contains723 entries\n",
      "Reading PostOffice2Week3Day4that contains872 entries\n",
      "Reading PostOffice2Week3Day5that contains604 entries\n",
      "Reading PostOffice2Week4Day1that contains1016 entries\n",
      "Reading PostOffice2Week4Day2that contains1008 entries\n",
      "Reading PostOffice2Week4Day3that contains890 entries\n",
      "Reading PostOffice2Week4Day4that contains947 entries\n",
      "Reading PostOffice2Week4Day5that contains900 entries\n",
      "Reading PostOffice3Week1Day1that contains766 entries\n",
      "Reading PostOffice3Week1Day2that contains929 entries\n",
      "Reading PostOffice3Week1Day3that contains920 entries\n",
      "Reading PostOffice3Week1Day4that contains877 entries\n",
      "Reading PostOffice3Week1Day5that contains789 entries\n",
      "Reading PostOffice3Week2Day1that contains875 entries\n",
      "Reading PostOffice3Week2Day2that contains922 entries\n",
      "Reading PostOffice3Week2Day3that contains909 entries\n",
      "Reading PostOffice3Week2Day4that contains1001 entries\n",
      "Reading PostOffice3Week2Day5that contains948 entries\n",
      "Reading PostOffice3Week3Day1that contains933 entries\n",
      "Reading PostOffice3Week3Day2that contains1010 entries\n",
      "Reading PostOffice3Week3Day3that contains873 entries\n",
      "Reading PostOffice3Week3Day4that contains761 entries\n",
      "Reading PostOffice3Week3Day5that contains630 entries\n",
      "Reading PostOffice3Week4Day1that contains988 entries\n",
      "Reading PostOffice3Week4Day2that contains783 entries\n",
      "Reading PostOffice3Week4Day3that contains647 entries\n",
      "Reading PostOffice3Week4Day4that contains890 entries\n",
      "Reading PostOffice3Week4Day5that contains751 entries\n",
      "50841\n"
     ]
    }
   ],
   "source": [
    "filenames = []\n",
    "rootFilePath = './PostOfficeDataCsv/'\n",
    "completeDataset = pd.DataFrame()\n",
    "\n",
    "for post_office in range(3):\n",
    "    for week in range(4):\n",
    "        if(post_office == 0 and week == 0):\n",
    "            i = 2\n",
    "        else:\n",
    "            i = 0\n",
    "            \n",
    "        for day in range(i,5):\n",
    "            filename = 'PostOffice' + str(post_office + 1) + 'Week' + str(week + 1) + 'Day' + str(day + 1)\n",
    "            fullPath = rootFilePath + filename + '.csv'\n",
    "            filenames.append(fullPath)\n",
    "            \n",
    "            numberOfRows = file_len(fullPath) - 1\n",
    "            print ('Reading ' + filename + 'that contains' + str(numberOfRows) + ' entries')\n",
    "            tempFeatures, tempArrivalTimes = file_read(rootFilePath + filename + '.csv', numberOfRows)\n",
    "            dfTempFeatures = pd.DataFrame(np.array(tempFeatures), columns=['hour', 'minutes', 'waitingTime', 'serviceTime'])\n",
    "            dfTempArrivalTimes = pd.DataFrame(np.array(tempArrivalTimes), columns=['arrivalTime'])\n",
    "            \n",
    "            timeLeavingTheQueue = []\n",
    "            for arrivalTime in range(numberOfRows):\n",
    "                timeLeavingTheQueue.append(dfTempArrivalTimes.at[arrivalTime, 'arrivalTime'] + pd.Timedelta(minutes = dfTempFeatures.at[arrivalTime, 'waitingTime']))\n",
    "            dftimeLeavingTheQueue = pd.DataFrame(np.array(timeLeavingTheQueue), columns=['timeLeavingTheQueue'])\n",
    "\n",
    "            waitingPeople = np.zeros(numberOfRows)\n",
    "            for i in range(numberOfRows):\n",
    "                for j in range(i):\n",
    "                    if (dfTempArrivalTimes.at[i, 'arrivalTime'] < dftimeLeavingTheQueue.at[j, 'timeLeavingTheQueue']):\n",
    "                        waitingPeople[i] += 1\n",
    "            dfWaitingPeople = pd.DataFrame(np.array(waitingPeople), columns=['waitingPeople'])\n",
    "            \n",
    "            dayOfWeek = np.zeros(numberOfRows)\n",
    "            for i in range(numberOfRows):\n",
    "                dayOfWeek[i] = day\n",
    "            dfDayOfWeek = pd.DataFrame(np.array(dayOfWeek), columns=['dayOfWeek'])\n",
    "            \n",
    "            dfWaitingPeople['waitingPeople'] = dfWaitingPeople['waitingPeople'].astype(int)\n",
    "            dfTempFeatures['hour'] = dfTempFeatures['hour'].astype(int)\n",
    "            dfTempFeatures['minutes'] = dfTempFeatures['minutes'].astype(int)\n",
    "            dfDayOfWeek['dayOfWeek'] = dfDayOfWeek['dayOfWeek'].astype(int)\n",
    "    \n",
    "            tempDataset = pd.concat([dfTempFeatures, dfWaitingPeople, dfDayOfWeek], axis=1)\n",
    "        \n",
    "            completeDataset = pd.concat([completeDataset, tempDataset], axis=0)\n",
    "          \n",
    "completeDataset = completeDataset.reset_index(drop = True)\n",
    "print(completeDataset.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 50841 rows and 6 columns.\n"
     ]
    }
   ],
   "source": [
    "print(f'The dataset has {completeDataset.shape[0]} rows and {completeDataset.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>minutes</th>\n",
       "      <th>waitingTime</th>\n",
       "      <th>serviceTime</th>\n",
       "      <th>waitingPeople</th>\n",
       "      <th>dayOfWeek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50836</th>\n",
       "      <td>14</td>\n",
       "      <td>57</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50837</th>\n",
       "      <td>14</td>\n",
       "      <td>57</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50838</th>\n",
       "      <td>14</td>\n",
       "      <td>58</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50839</th>\n",
       "      <td>14</td>\n",
       "      <td>59</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50840</th>\n",
       "      <td>14</td>\n",
       "      <td>59</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50841 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hour  minutes  waitingTime  serviceTime  waitingPeople  dayOfWeek\n",
       "0         8        0          4.0          5.0              0          2\n",
       "1         8        0          7.0          9.0              1          2\n",
       "2         8        0          5.0          7.0              2          2\n",
       "3         8        0          6.0          9.0              3          2\n",
       "4         8        0          4.0          5.0              4          2\n",
       "...     ...      ...          ...          ...            ...        ...\n",
       "50836    14       57         10.0         15.0             22          4\n",
       "50837    14       57         13.0         14.0             23          4\n",
       "50838    14       58          9.0         12.0             23          4\n",
       "50839    14       59          8.0         14.0             22          4\n",
       "50840    14       59         11.0         16.0             23          4\n",
       "\n",
       "[50841 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu = completeDataset[\"waitingPeople\"].mean()  # mean of distribution\n",
    "sigma = completeDataset[\"waitingPeople\"].std()  # standard deviation of distribution\n",
    "x = completeDataset[\"waitingPeople\"]\n",
    "\n",
    "num_bins = 111\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches = ax.hist(x, num_bins, density=1)\n",
    "\n",
    "# add a 'best fit' line\n",
    "y = ((1 / (np.sqrt(2 * np.pi) * sigma)) *\n",
    "     np.exp(-0.5 * (1 / sigma * (bins - mu))**2))\n",
    "ax.plot(bins, y, '--')\n",
    "ax.set_xlabel('Number of people waiting when joining the queue')\n",
    "ax.set_ylabel('Probability density')\n",
    "\n",
    "# Tweak spacing to prevent clipping of ylabel\n",
    "fig.tight_layout()\n",
    "# plt.savefig('./plots/waitingPeopleHistogram.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data to be plotted\n",
    "mu = completeDataset[\"waitingTime\"].mean()  # mean of distribution\n",
    "sigma = completeDataset[\"waitingTime\"].std()  # standard deviation of distribution\n",
    "x = completeDataset[\"waitingTime\"]\n",
    "\n",
    "num_bins = 33\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches = ax.hist(x, num_bins, density=1)\n",
    "\n",
    "# add a 'best fit' line\n",
    "y = ((1 / (np.sqrt(2 * np.pi) * sigma)) *\n",
    "     np.exp(-0.5 * (1 / sigma * (bins - mu))**2))\n",
    "ax.plot(bins, y, '--')\n",
    "ax.set_xlabel('Customer waiting time (mins)')\n",
    "ax.set_ylabel('Probability density')\n",
    "\n",
    "# Tweak spacing to prevent clipping of ylabel\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "workingCopyDataset = completeDataset\n",
    "workingCopyDataset.drop(['serviceTime'], axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean encoding for regression output\n",
    "def mean_encoder_regression(input_vector, output_vector):\n",
    "    assert len(input_vector) == len(output_vector)\n",
    "    numberOfRows = len(input_vector)\n",
    "\n",
    "    temp = pd.concat([input_vector, output_vector], axis=1)\n",
    "    # Compute target mean \n",
    "    averages = temp.groupby(by=input_vector.name)[output_vector.name].agg([\"mean\", \"count\"])\n",
    "    \n",
    "    print(averages)\n",
    "    return_vector = pd.DataFrame(0, index=np.arange(numberOfRows), columns={'feature'})\n",
    "\n",
    "    \n",
    "    for i in range(numberOfRows):\n",
    "        return_vector.iloc[i] = averages['mean'][input_vector.iloc[i]]\n",
    "        \n",
    "    return return_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           mean  count\n",
      "hour                  \n",
      "8     13.415349  11506\n",
      "9     13.543386   8528\n",
      "10    13.389851   5774\n",
      "11    13.839500   5595\n",
      "12    13.446889   6091\n",
      "13    13.546714   5630\n",
      "14    14.167552   7717\n",
      "              mean  count\n",
      "minutes                  \n",
      "0        13.497553   1226\n",
      "1        13.744149   1239\n",
      "2        13.718492    849\n",
      "3        13.720833    960\n",
      "4        13.970684    921\n",
      "5        13.467153   1096\n",
      "6        13.589231    650\n",
      "7        13.747307   1021\n",
      "8        13.239157    807\n",
      "9        13.681598    826\n",
      "10       13.472356    832\n",
      "11       13.740385   1144\n",
      "12       13.771353    761\n",
      "13       13.473318    862\n",
      "14       13.843750    800\n",
      "15       13.715686   1122\n",
      "16       13.747619    840\n",
      "17       13.868880   1205\n",
      "18       13.934605    734\n",
      "19       13.773643   1290\n",
      "20       13.536032   1013\n",
      "21       13.936396    849\n",
      "22       14.334370    643\n",
      "23       13.300094   1063\n",
      "24       13.846547    782\n",
      "25       13.338156   1106\n",
      "26       13.908189    806\n",
      "27       13.550314    954\n",
      "28       13.944694    669\n",
      "29       14.117771    951\n",
      "30       13.653141    764\n",
      "31       12.950000    760\n",
      "32       13.251337    748\n",
      "33       14.242932    955\n",
      "34       13.742251    613\n",
      "35       13.121860   1075\n",
      "36       13.369958    719\n",
      "37       13.133256    863\n",
      "38       13.439179    633\n",
      "39       13.325859    669\n",
      "40       13.500000    758\n",
      "41       14.587156    872\n",
      "42       14.005000    600\n",
      "43       13.232829    859\n",
      "44       13.352365    613\n",
      "45       13.682341    957\n",
      "46       13.369266    436\n",
      "47       13.460390    871\n",
      "48       13.557423    714\n",
      "49       13.241422    816\n",
      "50       13.397059    816\n",
      "51       13.668252    841\n",
      "52       13.474124    599\n",
      "53       13.110969    784\n",
      "54       13.506422    545\n",
      "55       13.370811    925\n",
      "56       13.487032    694\n",
      "57       13.826406    818\n",
      "58       13.993261    742\n",
      "59       12.915900    761\n",
      "                mean  count\n",
      "dayOfWeek                  \n",
      "0          14.483532  10171\n",
      "1          13.549747   9699\n",
      "2          13.092387  10456\n",
      "3          14.072759  10789\n",
      "4          12.815957   9726\n"
     ]
    }
   ],
   "source": [
    "encoded_input_vector_hour = mean_encoder_regression(workingCopyDataset['hour'], workingCopyDataset['waitingTime'])\n",
    "encoded_input_vector_hour.columns = ['hour']\n",
    "encoded_input_vector_minutes = mean_encoder_regression(workingCopyDataset['minutes'], workingCopyDataset['waitingTime'])\n",
    "encoded_input_vector_minutes.columns = ['minutes']\n",
    "encoded_input_vector_dayOfWeek = mean_encoder_regression(workingCopyDataset['dayOfWeek'], workingCopyDataset['waitingTime'])\n",
    "encoded_input_vector_dayOfWeek.columns = ['dayOfWeek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([encoded_input_vector_hour['hour'], encoded_input_vector_minutes['minutes'], pd.DataFrame(workingCopyDataset['waitingPeople']), encoded_input_vector_dayOfWeek['dayOfWeek']], axis=1)\n",
    "y = workingCopyDataset['waitingTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>minutes</th>\n",
       "      <th>waitingPeople</th>\n",
       "      <th>dayOfWeek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.415349</td>\n",
       "      <td>13.497553</td>\n",
       "      <td>0</td>\n",
       "      <td>13.092387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.415349</td>\n",
       "      <td>13.497553</td>\n",
       "      <td>1</td>\n",
       "      <td>13.092387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.415349</td>\n",
       "      <td>13.497553</td>\n",
       "      <td>2</td>\n",
       "      <td>13.092387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.415349</td>\n",
       "      <td>13.497553</td>\n",
       "      <td>3</td>\n",
       "      <td>13.092387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.415349</td>\n",
       "      <td>13.497553</td>\n",
       "      <td>4</td>\n",
       "      <td>13.092387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50836</th>\n",
       "      <td>14.167552</td>\n",
       "      <td>13.826406</td>\n",
       "      <td>22</td>\n",
       "      <td>12.815957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50837</th>\n",
       "      <td>14.167552</td>\n",
       "      <td>13.826406</td>\n",
       "      <td>23</td>\n",
       "      <td>12.815957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50838</th>\n",
       "      <td>14.167552</td>\n",
       "      <td>13.993261</td>\n",
       "      <td>23</td>\n",
       "      <td>12.815957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50839</th>\n",
       "      <td>14.167552</td>\n",
       "      <td>12.915900</td>\n",
       "      <td>22</td>\n",
       "      <td>12.815957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50840</th>\n",
       "      <td>14.167552</td>\n",
       "      <td>12.915900</td>\n",
       "      <td>23</td>\n",
       "      <td>12.815957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50841 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            hour    minutes  waitingPeople  dayOfWeek\n",
       "0      13.415349  13.497553              0  13.092387\n",
       "1      13.415349  13.497553              1  13.092387\n",
       "2      13.415349  13.497553              2  13.092387\n",
       "3      13.415349  13.497553              3  13.092387\n",
       "4      13.415349  13.497553              4  13.092387\n",
       "...          ...        ...            ...        ...\n",
       "50836  14.167552  13.826406             22  12.815957\n",
       "50837  14.167552  13.826406             23  12.815957\n",
       "50838  14.167552  13.993261             23  12.815957\n",
       "50839  14.167552  12.915900             22  12.815957\n",
       "50840  14.167552  12.915900             23  12.815957\n",
       "\n",
       "[50841 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40672, 4) (40672,)\n",
      "(10169, 4) (10169,)\n"
     ]
    }
   ],
   "source": [
    "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(trainX.shape, trainy.shape)\n",
    "print(testX.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_input(X, means, stds):\n",
    "    return (X - means) / stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "meansX = trainX.mean(axis=0)\n",
    "stdsX = trainX.std(axis=0) + 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_scaled = scale_input(trainX, meansX, stdsX)\n",
    "testX_scaled = scale_input(testX, meansX, stdsX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>minutes</th>\n",
       "      <th>waitingPeople</th>\n",
       "      <th>dayOfWeek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19060</th>\n",
       "      <td>-0.738627</td>\n",
       "      <td>2.254266</td>\n",
       "      <td>0.356732</td>\n",
       "      <td>0.751511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9683</th>\n",
       "      <td>-0.259424</td>\n",
       "      <td>1.577185</td>\n",
       "      <td>-0.689613</td>\n",
       "      <td>0.751511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14045</th>\n",
       "      <td>-0.246970</td>\n",
       "      <td>0.213726</td>\n",
       "      <td>-0.028763</td>\n",
       "      <td>-0.851344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20736</th>\n",
       "      <td>2.076619</td>\n",
       "      <td>0.336373</td>\n",
       "      <td>-0.414259</td>\n",
       "      <td>-1.303292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19593</th>\n",
       "      <td>-0.620582</td>\n",
       "      <td>-0.361592</td>\n",
       "      <td>-0.359188</td>\n",
       "      <td>0.751511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>2.076619</td>\n",
       "      <td>-1.169327</td>\n",
       "      <td>-1.295391</td>\n",
       "      <td>-1.303292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44732</th>\n",
       "      <td>-0.738627</td>\n",
       "      <td>-1.162249</td>\n",
       "      <td>0.797298</td>\n",
       "      <td>-0.851344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38158</th>\n",
       "      <td>-0.259424</td>\n",
       "      <td>-0.456621</td>\n",
       "      <td>1.017581</td>\n",
       "      <td>1.423101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>-0.246970</td>\n",
       "      <td>0.124771</td>\n",
       "      <td>-1.130179</td>\n",
       "      <td>-0.851344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>0.848828</td>\n",
       "      <td>1.968434</td>\n",
       "      <td>-0.909896</td>\n",
       "      <td>-1.303292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40672 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           hour   minutes  waitingPeople  dayOfWeek\n",
       "19060 -0.738627  2.254266       0.356732   0.751511\n",
       "9683  -0.259424  1.577185      -0.689613   0.751511\n",
       "14045 -0.246970  0.213726      -0.028763  -0.851344\n",
       "20736  2.076619  0.336373      -0.414259  -1.303292\n",
       "19593 -0.620582 -0.361592      -0.359188   0.751511\n",
       "...         ...       ...            ...        ...\n",
       "11284  2.076619 -1.169327      -1.295391  -1.303292\n",
       "44732 -0.738627 -1.162249       0.797298  -0.851344\n",
       "38158 -0.259424 -0.456621       1.017581   1.423101\n",
       "860   -0.246970  0.124771      -1.130179  -0.851344\n",
       "15795  0.848828  1.968434      -0.909896  -1.303292\n",
       "\n",
       "[40672 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/apoorvgupta/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/apoorvgupta/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                60        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 205\n",
      "Trainable params: 205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputVariables = 4\n",
    "nn_model = keras.models.Sequential()\n",
    "nn_model.add(keras.layers.Dense(12, input_dim=inputVariables, kernel_initializer='normal', activation='relu'))\n",
    "nn_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "nn_model.add(keras.layers.Dense(4, activation='relu'))\n",
    "nn_model.add(keras.layers.Dense(1, activation='linear'))\n",
    "nn_model.summary()\n",
    "\n",
    "nn_model.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32537 samples, validate on 8135 samples\n",
      "Epoch 1/500\n",
      "32537/32537 [==============================] - 1s 26us/sample - loss: 12.6488 - val_loss: 10.8374\n",
      "Epoch 2/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 6.6068 - val_loss: 4.0283\n",
      "Epoch 3/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.9087 - val_loss: 3.8470\n",
      "Epoch 4/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.8043 - val_loss: 3.7740\n",
      "Epoch 5/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.7470 - val_loss: 3.7213\n",
      "Epoch 6/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.7048 - val_loss: 3.6810\n",
      "Epoch 7/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.6742 - val_loss: 3.6621\n",
      "Epoch 8/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.6572 - val_loss: 3.6417\n",
      "Epoch 9/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.6413 - val_loss: 3.6250\n",
      "Epoch 10/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.6259 - val_loss: 3.6102\n",
      "Epoch 11/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.6134 - val_loss: 3.5976\n",
      "Epoch 12/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.6011 - val_loss: 3.5879\n",
      "Epoch 13/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5926 - val_loss: 3.5825\n",
      "Epoch 14/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5855 - val_loss: 3.5718\n",
      "Epoch 15/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5779 - val_loss: 3.5769\n",
      "Epoch 16/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5721 - val_loss: 3.5632\n",
      "Epoch 17/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5664 - val_loss: 3.5660\n",
      "Epoch 18/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5646 - val_loss: 3.5607\n",
      "Epoch 19/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5623 - val_loss: 3.5607\n",
      "Epoch 20/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5598 - val_loss: 3.5597\n",
      "Epoch 21/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5583 - val_loss: 3.5612\n",
      "Epoch 22/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5565 - val_loss: 3.5581\n",
      "Epoch 23/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5547 - val_loss: 3.5536\n",
      "Epoch 24/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5535 - val_loss: 3.5593\n",
      "Epoch 25/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5504 - val_loss: 3.5560\n",
      "Epoch 26/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5497 - val_loss: 3.5619\n",
      "Epoch 27/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5482 - val_loss: 3.5562\n",
      "Epoch 28/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5460 - val_loss: 3.5522\n",
      "Epoch 29/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5461 - val_loss: 3.5530\n",
      "Epoch 30/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5470 - val_loss: 3.5516\n",
      "Epoch 31/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5461 - val_loss: 3.5538\n",
      "Epoch 32/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5425 - val_loss: 3.5524\n",
      "Epoch 33/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5449 - val_loss: 3.5448\n",
      "Epoch 34/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5426 - val_loss: 3.5534\n",
      "Epoch 35/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5419 - val_loss: 3.5514\n",
      "Epoch 36/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5414 - val_loss: 3.5564\n",
      "Epoch 37/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5431 - val_loss: 3.5484\n",
      "Epoch 38/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5414 - val_loss: 3.5514\n",
      "Epoch 39/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5404 - val_loss: 3.5456\n",
      "Epoch 40/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5397 - val_loss: 3.5475\n",
      "Epoch 41/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5388 - val_loss: 3.5482\n",
      "Epoch 42/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5391 - val_loss: 3.5473\n",
      "Epoch 43/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5392 - val_loss: 3.5455\n",
      "Epoch 44/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5389 - val_loss: 3.5518\n",
      "Epoch 45/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5370 - val_loss: 3.5414\n",
      "Epoch 46/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5407 - val_loss: 3.5488\n",
      "Epoch 47/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5369 - val_loss: 3.5436\n",
      "Epoch 48/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5376 - val_loss: 3.5424\n",
      "Epoch 49/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5391 - val_loss: 3.5553\n",
      "Epoch 50/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5384 - val_loss: 3.5470\n",
      "Epoch 51/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5378 - val_loss: 3.5423\n",
      "Epoch 52/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5370 - val_loss: 3.5491\n",
      "Epoch 53/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5373 - val_loss: 3.5417\n",
      "Epoch 54/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5381 - val_loss: 3.5446\n",
      "Epoch 55/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5372 - val_loss: 3.5444\n",
      "Epoch 56/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5373 - val_loss: 3.5456\n",
      "Epoch 57/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5371 - val_loss: 3.5465\n",
      "Epoch 58/500\n",
      "32537/32537 [==============================] - 0s 5us/sample - loss: 3.5395 - val_loss: 3.5508\n",
      "Epoch 59/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5370 - val_loss: 3.5489\n",
      "Epoch 60/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5362 - val_loss: 3.5432\n",
      "Epoch 61/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5373 - val_loss: 3.5441\n",
      "Epoch 62/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5369 - val_loss: 3.5447\n",
      "Epoch 63/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5353 - val_loss: 3.5441\n",
      "Epoch 64/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5351 - val_loss: 3.5425\n",
      "Epoch 65/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5359 - val_loss: 3.5444\n",
      "Epoch 66/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5377 - val_loss: 3.5468\n",
      "Epoch 67/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5356 - val_loss: 3.5625\n",
      "Epoch 68/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5360 - val_loss: 3.5461\n",
      "Epoch 69/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5360 - val_loss: 3.5486\n",
      "Epoch 70/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5370 - val_loss: 3.5456\n",
      "Epoch 71/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5339 - val_loss: 3.5441\n",
      "Epoch 72/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5372 - val_loss: 3.5478\n",
      "Epoch 73/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5351 - val_loss: 3.5444\n",
      "Epoch 74/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5342 - val_loss: 3.5449\n",
      "Epoch 75/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5347 - val_loss: 3.5415\n",
      "Epoch 76/500\n",
      "32537/32537 [==============================] - 0s 5us/sample - loss: 3.5342 - val_loss: 3.5422\n",
      "Epoch 77/500\n",
      "32537/32537 [==============================] - 0s 5us/sample - loss: 3.5348 - val_loss: 3.5440\n",
      "Epoch 78/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5358 - val_loss: 3.5483\n",
      "Epoch 79/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5378 - val_loss: 3.5469\n",
      "Epoch 80/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5347 - val_loss: 3.5437\n",
      "Epoch 81/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5362 - val_loss: 3.5403\n",
      "Epoch 82/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5364 - val_loss: 3.5429\n",
      "Epoch 83/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5366 - val_loss: 3.5449\n",
      "Epoch 84/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5357 - val_loss: 3.5433\n",
      "Epoch 85/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5357 - val_loss: 3.5444\n",
      "Epoch 86/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5351 - val_loss: 3.5487\n",
      "Epoch 87/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5346 - val_loss: 3.5484\n",
      "Epoch 88/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5351 - val_loss: 3.5423\n",
      "Epoch 89/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5358 - val_loss: 3.5445\n",
      "Epoch 90/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5335 - val_loss: 3.5485\n",
      "Epoch 91/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5354 - val_loss: 3.5437\n",
      "Epoch 92/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5366 - val_loss: 3.5441\n",
      "Epoch 93/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5352 - val_loss: 3.5417\n",
      "Epoch 94/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5343 - val_loss: 3.5457\n",
      "Epoch 95/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5360 - val_loss: 3.5499\n",
      "Epoch 96/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5331 - val_loss: 3.5426\n",
      "Epoch 97/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5347 - val_loss: 3.5507\n",
      "Epoch 98/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5342 - val_loss: 3.5405\n",
      "Epoch 99/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5346 - val_loss: 3.5517\n",
      "Epoch 100/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5351 - val_loss: 3.5435\n",
      "Epoch 101/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5324 - val_loss: 3.5417\n",
      "Epoch 102/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5334 - val_loss: 3.5411\n",
      "Epoch 103/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5347 - val_loss: 3.5449\n",
      "Epoch 104/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5347 - val_loss: 3.5421\n",
      "Epoch 105/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5333 - val_loss: 3.5535\n",
      "Epoch 106/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5370 - val_loss: 3.5500\n",
      "Epoch 107/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5338 - val_loss: 3.5437\n",
      "Epoch 108/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5336 - val_loss: 3.5555\n",
      "Epoch 109/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5348 - val_loss: 3.5452\n",
      "Epoch 110/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5334 - val_loss: 3.5408\n",
      "Epoch 111/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5326 - val_loss: 3.5420\n",
      "Epoch 112/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5329 - val_loss: 3.5462\n",
      "Epoch 113/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5319 - val_loss: 3.5512\n",
      "Epoch 114/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5327 - val_loss: 3.5431\n",
      "Epoch 115/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5359 - val_loss: 3.5416\n",
      "Epoch 116/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5335 - val_loss: 3.5471\n",
      "Epoch 117/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5340 - val_loss: 3.5412\n",
      "Epoch 118/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5329 - val_loss: 3.5408\n",
      "Epoch 119/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5320 - val_loss: 3.5392\n",
      "Epoch 120/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5320 - val_loss: 3.5451\n",
      "Epoch 121/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5324 - val_loss: 3.5625\n",
      "Epoch 122/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5346 - val_loss: 3.5422\n",
      "Epoch 123/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5321 - val_loss: 3.5446\n",
      "Epoch 124/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5338 - val_loss: 3.5458\n",
      "Epoch 125/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5339 - val_loss: 3.5401\n",
      "Epoch 126/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5331 - val_loss: 3.5445\n",
      "Epoch 127/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5321 - val_loss: 3.5430\n",
      "Epoch 128/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5319 - val_loss: 3.5378\n",
      "Epoch 129/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5324 - val_loss: 3.5441\n",
      "Epoch 130/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5322 - val_loss: 3.5409\n",
      "Epoch 131/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5314 - val_loss: 3.5423\n",
      "Epoch 132/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5330 - val_loss: 3.5443\n",
      "Epoch 133/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5311 - val_loss: 3.5420\n",
      "Epoch 134/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5308 - val_loss: 3.5510\n",
      "Epoch 135/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5323 - val_loss: 3.5397\n",
      "Epoch 136/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5320 - val_loss: 3.5544\n",
      "Epoch 137/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5329 - val_loss: 3.5406\n",
      "Epoch 138/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5316 - val_loss: 3.5564\n",
      "Epoch 139/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5314 - val_loss: 3.5429\n",
      "Epoch 140/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5314 - val_loss: 3.5469\n",
      "Epoch 141/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5324 - val_loss: 3.5430\n",
      "Epoch 142/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5320 - val_loss: 3.5391\n",
      "Epoch 143/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5353 - val_loss: 3.5373\n",
      "Epoch 144/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5313 - val_loss: 3.5405\n",
      "Epoch 145/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5326 - val_loss: 3.5442\n",
      "Epoch 146/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5311 - val_loss: 3.5405\n",
      "Epoch 147/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5301 - val_loss: 3.5431\n",
      "Epoch 148/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5306 - val_loss: 3.5378\n",
      "Epoch 149/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5301 - val_loss: 3.5365\n",
      "Epoch 150/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5310 - val_loss: 3.5410\n",
      "Epoch 151/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5280 - val_loss: 3.5466\n",
      "Epoch 152/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5313 - val_loss: 3.5474\n",
      "Epoch 153/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5320 - val_loss: 3.5433\n",
      "Epoch 154/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5298 - val_loss: 3.5497\n",
      "Epoch 155/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5322 - val_loss: 3.5386\n",
      "Epoch 156/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5291 - val_loss: 3.5548\n",
      "Epoch 157/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5288 - val_loss: 3.5466\n",
      "Epoch 158/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5289 - val_loss: 3.5446\n",
      "Epoch 159/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5300 - val_loss: 3.5393\n",
      "Epoch 160/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5308 - val_loss: 3.5401\n",
      "Epoch 161/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5299 - val_loss: 3.5374\n",
      "Epoch 162/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5287 - val_loss: 3.5408\n",
      "Epoch 163/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5287 - val_loss: 3.5408\n",
      "Epoch 164/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5313 - val_loss: 3.5380\n",
      "Epoch 165/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5299 - val_loss: 3.5360\n",
      "Epoch 166/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5301 - val_loss: 3.5353\n",
      "Epoch 167/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5304 - val_loss: 3.5494\n",
      "Epoch 168/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5310 - val_loss: 3.5432\n",
      "Epoch 169/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5316 - val_loss: 3.5363\n",
      "Epoch 170/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5302 - val_loss: 3.5370\n",
      "Epoch 171/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5302 - val_loss: 3.5343\n",
      "Epoch 172/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5301 - val_loss: 3.5369\n",
      "Epoch 173/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5301 - val_loss: 3.5378\n",
      "Epoch 174/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5295 - val_loss: 3.5466\n",
      "Epoch 175/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5288 - val_loss: 3.5424\n",
      "Epoch 176/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5301 - val_loss: 3.5383\n",
      "Epoch 177/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5290 - val_loss: 3.5384\n",
      "Epoch 178/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5271 - val_loss: 3.5388\n",
      "Epoch 179/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5298 - val_loss: 3.5361\n",
      "Epoch 180/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5299 - val_loss: 3.5377\n",
      "Epoch 181/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5293 - val_loss: 3.5454\n",
      "Epoch 182/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5279 - val_loss: 3.5357\n",
      "Epoch 183/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5291 - val_loss: 3.5361\n",
      "Epoch 184/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5281 - val_loss: 3.5490\n",
      "Epoch 185/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5288 - val_loss: 3.5414\n",
      "Epoch 186/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5271 - val_loss: 3.5368\n",
      "Epoch 187/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5275 - val_loss: 3.5368\n",
      "Epoch 188/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5299 - val_loss: 3.5367\n",
      "Epoch 189/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5286 - val_loss: 3.5358\n",
      "Epoch 190/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5279 - val_loss: 3.5432\n",
      "Epoch 191/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5300 - val_loss: 3.5362\n",
      "Epoch 192/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5283 - val_loss: 3.5363\n",
      "Epoch 193/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5273 - val_loss: 3.5411\n",
      "Epoch 194/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5292 - val_loss: 3.5409\n",
      "Epoch 195/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5281 - val_loss: 3.5391\n",
      "Epoch 196/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5289 - val_loss: 3.5360\n",
      "Epoch 197/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5299 - val_loss: 3.5364\n",
      "Epoch 198/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5288 - val_loss: 3.5398\n",
      "Epoch 199/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5296 - val_loss: 3.5378\n",
      "Epoch 200/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5285 - val_loss: 3.5407\n",
      "Epoch 201/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5303 - val_loss: 3.5421\n",
      "Epoch 202/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5272 - val_loss: 3.5330\n",
      "Epoch 203/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5276 - val_loss: 3.5350\n",
      "Epoch 204/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5301 - val_loss: 3.5450\n",
      "Epoch 205/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5334 - val_loss: 3.5453\n",
      "Epoch 206/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5274 - val_loss: 3.5450\n",
      "Epoch 207/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5283 - val_loss: 3.5366\n",
      "Epoch 208/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5291 - val_loss: 3.5409\n",
      "Epoch 209/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5264 - val_loss: 3.5330\n",
      "Epoch 210/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5274 - val_loss: 3.5374\n",
      "Epoch 211/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5280 - val_loss: 3.5435\n",
      "Epoch 212/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5273 - val_loss: 3.5372\n",
      "Epoch 213/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5291 - val_loss: 3.5367\n",
      "Epoch 214/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5306 - val_loss: 3.5428\n",
      "Epoch 215/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5269 - val_loss: 3.5341\n",
      "Epoch 216/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5267 - val_loss: 3.5347\n",
      "Epoch 217/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5282 - val_loss: 3.5423\n",
      "Epoch 218/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5276 - val_loss: 3.5507\n",
      "Epoch 219/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5311 - val_loss: 3.5370\n",
      "Epoch 220/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5286 - val_loss: 3.5351\n",
      "Epoch 221/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5268 - val_loss: 3.5427\n",
      "Epoch 222/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5285 - val_loss: 3.5393\n",
      "Epoch 223/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5271 - val_loss: 3.5416\n",
      "Epoch 224/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5300 - val_loss: 3.5346\n",
      "Epoch 225/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5269 - val_loss: 3.5410\n",
      "Epoch 226/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5274 - val_loss: 3.5412\n",
      "Epoch 227/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5267 - val_loss: 3.5494\n",
      "Epoch 228/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5268 - val_loss: 3.5335\n",
      "Epoch 229/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5290 - val_loss: 3.5343\n",
      "Epoch 230/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5284 - val_loss: 3.5375\n",
      "Epoch 231/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5280 - val_loss: 3.5379\n",
      "Epoch 232/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5282 - val_loss: 3.5356\n",
      "Epoch 233/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5262 - val_loss: 3.5353\n",
      "Epoch 234/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5263 - val_loss: 3.5398\n",
      "Epoch 235/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5258 - val_loss: 3.5428\n",
      "Epoch 236/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5276 - val_loss: 3.5379\n",
      "Epoch 237/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5273 - val_loss: 3.5368\n",
      "Epoch 238/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5278 - val_loss: 3.5356\n",
      "Epoch 239/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5302 - val_loss: 3.5344\n",
      "Epoch 240/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5260 - val_loss: 3.5364\n",
      "Epoch 241/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5281 - val_loss: 3.5352\n",
      "Epoch 242/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5266 - val_loss: 3.5368\n",
      "Epoch 243/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5264 - val_loss: 3.5343\n",
      "Epoch 244/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5275 - val_loss: 3.5355\n",
      "Epoch 245/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5286 - val_loss: 3.5375\n",
      "Epoch 246/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5275 - val_loss: 3.5373\n",
      "Epoch 247/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5272 - val_loss: 3.5359\n",
      "Epoch 248/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5270 - val_loss: 3.5375\n",
      "Epoch 249/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5263 - val_loss: 3.5384\n",
      "Epoch 250/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5265 - val_loss: 3.5341\n",
      "Epoch 251/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5268 - val_loss: 3.5405\n",
      "Epoch 252/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5266 - val_loss: 3.5390\n",
      "Epoch 253/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5260 - val_loss: 3.5399\n",
      "Epoch 254/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5258 - val_loss: 3.5455\n",
      "Epoch 255/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5256 - val_loss: 3.5338\n",
      "Epoch 256/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5267 - val_loss: 3.5399\n",
      "Epoch 257/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5266 - val_loss: 3.5374\n",
      "Epoch 258/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5263 - val_loss: 3.5370\n",
      "Epoch 259/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5267 - val_loss: 3.5375\n",
      "Epoch 260/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5254 - val_loss: 3.5345\n",
      "Epoch 261/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5265 - val_loss: 3.5402\n",
      "Epoch 262/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5265 - val_loss: 3.5464\n",
      "Epoch 263/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5263 - val_loss: 3.5435\n",
      "Epoch 264/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5290 - val_loss: 3.5400\n",
      "Epoch 265/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5251 - val_loss: 3.5338\n",
      "Epoch 266/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5270 - val_loss: 3.5390\n",
      "Epoch 267/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5280 - val_loss: 3.5388\n",
      "Epoch 268/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5260 - val_loss: 3.5392\n",
      "Epoch 269/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5259 - val_loss: 3.5384\n",
      "Epoch 270/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5261 - val_loss: 3.5341\n",
      "Epoch 271/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5266 - val_loss: 3.5348\n",
      "Epoch 272/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5252 - val_loss: 3.5354\n",
      "Epoch 273/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5269 - val_loss: 3.5405\n",
      "Epoch 274/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5275 - val_loss: 3.5353\n",
      "Epoch 275/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5264 - val_loss: 3.5354\n",
      "Epoch 276/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5248 - val_loss: 3.5347\n",
      "Epoch 277/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5275 - val_loss: 3.5326\n",
      "Epoch 278/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5266 - val_loss: 3.5358\n",
      "Epoch 279/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5258 - val_loss: 3.5381\n",
      "Epoch 280/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5263 - val_loss: 3.5393\n",
      "Epoch 281/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5270 - val_loss: 3.5313\n",
      "Epoch 282/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5273 - val_loss: 3.5411\n",
      "Epoch 283/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5277 - val_loss: 3.5379\n",
      "Epoch 284/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5249 - val_loss: 3.5371\n",
      "Epoch 285/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5257 - val_loss: 3.5330\n",
      "Epoch 286/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5263 - val_loss: 3.5312\n",
      "Epoch 287/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5263 - val_loss: 3.5360\n",
      "Epoch 288/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5260 - val_loss: 3.5371\n",
      "Epoch 289/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5237 - val_loss: 3.5417\n",
      "Epoch 290/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5260 - val_loss: 3.5411\n",
      "Epoch 291/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5276 - val_loss: 3.5364\n",
      "Epoch 292/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5258 - val_loss: 3.5411\n",
      "Epoch 293/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5247 - val_loss: 3.5371\n",
      "Epoch 294/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5248 - val_loss: 3.5341\n",
      "Epoch 295/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5247 - val_loss: 3.5405\n",
      "Epoch 296/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5239 - val_loss: 3.5398\n",
      "Epoch 297/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5269 - val_loss: 3.5363\n",
      "Epoch 298/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5257 - val_loss: 3.5415\n",
      "Epoch 299/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5262 - val_loss: 3.5342\n",
      "Epoch 300/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5255 - val_loss: 3.5381\n",
      "Epoch 301/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5260 - val_loss: 3.5394\n",
      "Epoch 302/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5243 - val_loss: 3.5349\n",
      "Epoch 303/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5254 - val_loss: 3.5373\n",
      "Epoch 304/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5254 - val_loss: 3.5341\n",
      "Epoch 305/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5257 - val_loss: 3.5369\n",
      "Epoch 306/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5264 - val_loss: 3.5352\n",
      "Epoch 307/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5279 - val_loss: 3.5422\n",
      "Epoch 308/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5232 - val_loss: 3.5367\n",
      "Epoch 309/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5253 - val_loss: 3.5403\n",
      "Epoch 310/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5239 - val_loss: 3.5312\n",
      "Epoch 311/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5257 - val_loss: 3.5318\n",
      "Epoch 312/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5256 - val_loss: 3.5414\n",
      "Epoch 313/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5266 - val_loss: 3.5420\n",
      "Epoch 314/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5259 - val_loss: 3.5369\n",
      "Epoch 315/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5239 - val_loss: 3.5362\n",
      "Epoch 316/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5259 - val_loss: 3.5453\n",
      "Epoch 317/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5283 - val_loss: 3.5375\n",
      "Epoch 318/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5255 - val_loss: 3.5391\n",
      "Epoch 319/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5258 - val_loss: 3.5354\n",
      "Epoch 320/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5262 - val_loss: 3.5312\n",
      "Epoch 321/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5257 - val_loss: 3.5379\n",
      "Epoch 322/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5253 - val_loss: 3.5386\n",
      "Epoch 323/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5239 - val_loss: 3.5330\n",
      "Epoch 324/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5245 - val_loss: 3.5428\n",
      "Epoch 325/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5246 - val_loss: 3.5543\n",
      "Epoch 326/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5265 - val_loss: 3.5319\n",
      "Epoch 327/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5258 - val_loss: 3.5327\n",
      "Epoch 328/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5253 - val_loss: 3.5302\n",
      "Epoch 329/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5252 - val_loss: 3.5286\n",
      "Epoch 330/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5250 - val_loss: 3.5372\n",
      "Epoch 331/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5243 - val_loss: 3.5318\n",
      "Epoch 332/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5235 - val_loss: 3.5330\n",
      "Epoch 333/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5250 - val_loss: 3.5340\n",
      "Epoch 334/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5237 - val_loss: 3.5519\n",
      "Epoch 335/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5246 - val_loss: 3.5359\n",
      "Epoch 336/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5236 - val_loss: 3.5358\n",
      "Epoch 337/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5246 - val_loss: 3.5353\n",
      "Epoch 338/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5239 - val_loss: 3.5334\n",
      "Epoch 339/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5244 - val_loss: 3.5392\n",
      "Epoch 340/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5241 - val_loss: 3.5349\n",
      "Epoch 341/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5260 - val_loss: 3.5387\n",
      "Epoch 342/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5267 - val_loss: 3.5404\n",
      "Epoch 343/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5269 - val_loss: 3.5352\n",
      "Epoch 344/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5239 - val_loss: 3.5367\n",
      "Epoch 345/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5253 - val_loss: 3.5390\n",
      "Epoch 346/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5243 - val_loss: 3.5364\n",
      "Epoch 347/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5253 - val_loss: 3.5410\n",
      "Epoch 348/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5265 - val_loss: 3.5414\n",
      "Epoch 349/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5253 - val_loss: 3.5311\n",
      "Epoch 350/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5241 - val_loss: 3.5409\n",
      "Epoch 351/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5276 - val_loss: 3.5331\n",
      "Epoch 352/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5252 - val_loss: 3.5312\n",
      "Epoch 353/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5254 - val_loss: 3.5336\n",
      "Epoch 354/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5255 - val_loss: 3.5381\n",
      "Epoch 355/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5236 - val_loss: 3.5325\n",
      "Epoch 356/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5262 - val_loss: 3.5347\n",
      "Epoch 357/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5235 - val_loss: 3.5349\n",
      "Epoch 358/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5246 - val_loss: 3.5371\n",
      "Epoch 359/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5251 - val_loss: 3.5399\n",
      "Epoch 360/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5264 - val_loss: 3.5328\n",
      "Epoch 361/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5238 - val_loss: 3.5351\n",
      "Epoch 362/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5247 - val_loss: 3.5347\n",
      "Epoch 363/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5257 - val_loss: 3.5357\n",
      "Epoch 364/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5256 - val_loss: 3.5330\n",
      "Epoch 365/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5240 - val_loss: 3.5323\n",
      "Epoch 366/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5247 - val_loss: 3.5369\n",
      "Epoch 367/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5231 - val_loss: 3.5360\n",
      "Epoch 368/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5227 - val_loss: 3.5360\n",
      "Epoch 369/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5264 - val_loss: 3.5438\n",
      "Epoch 370/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5254 - val_loss: 3.5343\n",
      "Epoch 371/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5236 - val_loss: 3.5396\n",
      "Epoch 372/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5245 - val_loss: 3.5332\n",
      "Epoch 373/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5233 - val_loss: 3.5406\n",
      "Epoch 374/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5253 - val_loss: 3.5401\n",
      "Epoch 375/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5251 - val_loss: 3.5371\n",
      "Epoch 376/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5237 - val_loss: 3.5308\n",
      "Epoch 377/500\n",
      "32537/32537 [==============================] - 0s 5us/sample - loss: 3.5229 - val_loss: 3.5343\n",
      "Epoch 378/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5263 - val_loss: 3.5338\n",
      "Epoch 379/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5246 - val_loss: 3.5378\n",
      "Epoch 380/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5230 - val_loss: 3.5336\n",
      "Epoch 381/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5249 - val_loss: 3.5342\n",
      "Epoch 382/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5255 - val_loss: 3.5359\n",
      "Epoch 383/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5247 - val_loss: 3.5384\n",
      "Epoch 384/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5239 - val_loss: 3.5353\n",
      "Epoch 385/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5250 - val_loss: 3.5309\n",
      "Epoch 386/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5254 - val_loss: 3.5300\n",
      "Epoch 387/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5232 - val_loss: 3.5321\n",
      "Epoch 388/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5241 - val_loss: 3.5300\n",
      "Epoch 389/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5226 - val_loss: 3.5367\n",
      "Epoch 390/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5251 - val_loss: 3.5362\n",
      "Epoch 391/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5244 - val_loss: 3.5353\n",
      "Epoch 392/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5231 - val_loss: 3.5391\n",
      "Epoch 393/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5247 - val_loss: 3.5302\n",
      "Epoch 394/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5244 - val_loss: 3.5345\n",
      "Epoch 395/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5232 - val_loss: 3.5383\n",
      "Epoch 396/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5255 - val_loss: 3.5369\n",
      "Epoch 397/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5236 - val_loss: 3.5356\n",
      "Epoch 398/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5227 - val_loss: 3.5317\n",
      "Epoch 399/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5254 - val_loss: 3.5406\n",
      "Epoch 400/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5240 - val_loss: 3.5325\n",
      "Epoch 401/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5242 - val_loss: 3.5396\n",
      "Epoch 402/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5243 - val_loss: 3.5342\n",
      "Epoch 403/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5246 - val_loss: 3.5347\n",
      "Epoch 404/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5231 - val_loss: 3.5408\n",
      "Epoch 405/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5236 - val_loss: 3.5352\n",
      "Epoch 406/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5252 - val_loss: 3.5316\n",
      "Epoch 407/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5246 - val_loss: 3.5311\n",
      "Epoch 408/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5247 - val_loss: 3.5354\n",
      "Epoch 409/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5262 - val_loss: 3.5341\n",
      "Epoch 410/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5245 - val_loss: 3.5356\n",
      "Epoch 411/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5240 - val_loss: 3.5356\n",
      "Epoch 412/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5236 - val_loss: 3.5339\n",
      "Epoch 413/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5250 - val_loss: 3.5409\n",
      "Epoch 414/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5233 - val_loss: 3.5334\n",
      "Epoch 415/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5230 - val_loss: 3.5306\n",
      "Epoch 416/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5244 - val_loss: 3.5355\n",
      "Epoch 417/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5234 - val_loss: 3.5346\n",
      "Epoch 418/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5230 - val_loss: 3.5409\n",
      "Epoch 419/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5255 - val_loss: 3.5297\n",
      "Epoch 420/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5248 - val_loss: 3.5363\n",
      "Epoch 421/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5240 - val_loss: 3.5335\n",
      "Epoch 422/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5242 - val_loss: 3.5302\n",
      "Epoch 423/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5242 - val_loss: 3.5345\n",
      "Epoch 424/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5232 - val_loss: 3.5307\n",
      "Epoch 425/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5227 - val_loss: 3.5333\n",
      "Epoch 426/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5245 - val_loss: 3.5318\n",
      "Epoch 427/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5235 - val_loss: 3.5374\n",
      "Epoch 428/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5244 - val_loss: 3.5354\n",
      "Epoch 429/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5229 - val_loss: 3.5334\n",
      "Epoch 430/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5235 - val_loss: 3.5352\n",
      "Epoch 431/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5243 - val_loss: 3.5347\n",
      "Epoch 432/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5252 - val_loss: 3.5299\n",
      "Epoch 433/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5261 - val_loss: 3.5328\n",
      "Epoch 434/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5230 - val_loss: 3.5372\n",
      "Epoch 435/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5250 - val_loss: 3.5338\n",
      "Epoch 436/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5236 - val_loss: 3.5307\n",
      "Epoch 437/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5228 - val_loss: 3.5315\n",
      "Epoch 438/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5234 - val_loss: 3.5330\n",
      "Epoch 439/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5252 - val_loss: 3.5320\n",
      "Epoch 440/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5231 - val_loss: 3.5485\n",
      "Epoch 441/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5236 - val_loss: 3.5308\n",
      "Epoch 442/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5239 - val_loss: 3.5422\n",
      "Epoch 443/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5255 - val_loss: 3.5380\n",
      "Epoch 444/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5227 - val_loss: 3.5340\n",
      "Epoch 445/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5245 - val_loss: 3.5357\n",
      "Epoch 446/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5218 - val_loss: 3.5301\n",
      "Epoch 447/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5224 - val_loss: 3.5370\n",
      "Epoch 448/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5242 - val_loss: 3.5329\n",
      "Epoch 449/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5233 - val_loss: 3.5324\n",
      "Epoch 450/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5244 - val_loss: 3.5317\n",
      "Epoch 451/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5238 - val_loss: 3.5384\n",
      "Epoch 452/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5235 - val_loss: 3.5304\n",
      "Epoch 453/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5243 - val_loss: 3.5322\n",
      "Epoch 454/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5243 - val_loss: 3.5306\n",
      "Epoch 455/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5223 - val_loss: 3.5359\n",
      "Epoch 456/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5240 - val_loss: 3.5306\n",
      "Epoch 457/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5275 - val_loss: 3.5349\n",
      "Epoch 458/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5235 - val_loss: 3.5381\n",
      "Epoch 459/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5227 - val_loss: 3.5359\n",
      "Epoch 460/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5242 - val_loss: 3.5325\n",
      "Epoch 461/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5216 - val_loss: 3.5297\n",
      "Epoch 462/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5215 - val_loss: 3.5321\n",
      "Epoch 463/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5233 - val_loss: 3.5280\n",
      "Epoch 464/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5248 - val_loss: 3.5320\n",
      "Epoch 465/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5251 - val_loss: 3.5274\n",
      "Epoch 466/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5225 - val_loss: 3.5316\n",
      "Epoch 467/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5232 - val_loss: 3.5322\n",
      "Epoch 468/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5236 - val_loss: 3.5330\n",
      "Epoch 469/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5218 - val_loss: 3.5324\n",
      "Epoch 470/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5229 - val_loss: 3.5299\n",
      "Epoch 471/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5235 - val_loss: 3.5295\n",
      "Epoch 472/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5229 - val_loss: 3.5319\n",
      "Epoch 473/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5228 - val_loss: 3.5399\n",
      "Epoch 474/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5254 - val_loss: 3.5322\n",
      "Epoch 475/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5222 - val_loss: 3.5303\n",
      "Epoch 476/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5253 - val_loss: 3.5315\n",
      "Epoch 477/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5234 - val_loss: 3.5287\n",
      "Epoch 478/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5224 - val_loss: 3.5341\n",
      "Epoch 479/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5233 - val_loss: 3.5424\n",
      "Epoch 480/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5236 - val_loss: 3.5349\n",
      "Epoch 481/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5228 - val_loss: 3.5314\n",
      "Epoch 482/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5209 - val_loss: 3.5335\n",
      "Epoch 483/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5235 - val_loss: 3.5337\n",
      "Epoch 484/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5226 - val_loss: 3.5357\n",
      "Epoch 485/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5224 - val_loss: 3.5301\n",
      "Epoch 486/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5239 - val_loss: 3.5301\n",
      "Epoch 487/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5238 - val_loss: 3.5398\n",
      "Epoch 488/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5240 - val_loss: 3.5333\n",
      "Epoch 489/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5238 - val_loss: 3.5352\n",
      "Epoch 490/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5232 - val_loss: 3.5296\n",
      "Epoch 491/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5243 - val_loss: 3.5295\n",
      "Epoch 492/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5222 - val_loss: 3.5279\n",
      "Epoch 493/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5243 - val_loss: 3.5306\n",
      "Epoch 494/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5231 - val_loss: 3.5374\n",
      "Epoch 495/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5223 - val_loss: 3.5334\n",
      "Epoch 496/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5234 - val_loss: 3.5308\n",
      "Epoch 497/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5238 - val_loss: 3.5326\n",
      "Epoch 498/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5231 - val_loss: 3.5268\n",
      "Epoch 499/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5223 - val_loss: 3.5294\n",
      "Epoch 500/500\n",
      "32537/32537 [==============================] - 0s 6us/sample - loss: 3.5240 - val_loss: 3.5305\n"
     ]
    }
   ],
   "source": [
    "numberOfEpochs = 500\n",
    "batchSize = 256\n",
    "history = nn_model.fit(trainX_scaled, trainy, epochs=numberOfEpochs, batch_size=batchSize, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.118307],\n",
       "       [10.923872],\n",
       "       [15.581464],\n",
       "       ...,\n",
       "       [12.30162 ],\n",
       "       [11.524996],\n",
       "       [10.1324  ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network_predict_test = nn_model.predict(testX_scaled)\n",
    "neural_network_predict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5093337908315383"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net_mae = mean_absolute_error(neural_network_predict_test,testy)\n",
    "neural_net_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "randomForestRegressorModel = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "randomForestRegressorModel.fit(trainX_scaled,trainy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.10366667, 10.12666667, 17.51      , ..., 16.95309524,\n",
       "        8.9047381 , 11.736     ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_test_predict = randomForestRegressorModel.predict(testX_scaled)\n",
    "random_forest_test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3399202534769477"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_mae = mean_absolute_error(random_forest_test_predict,testy)\n",
    "random_forest_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.6\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
